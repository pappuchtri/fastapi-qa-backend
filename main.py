from fastapi import FastAPI, Depends, HTTPException, status, File, UploadFile, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from sqlalchemy.orm import Session
from sqlalchemy import text
from typing import List, Optional
import os
import uuid
from datetime import datetime
import uvicorn
from dotenv import load_dotenv
import logging
from contextlib import asynccontextmanager

# Load environment variables
load_dotenv()

# Import our modules
from database import SessionLocal, engine, get_db, Base
from models import Question, Answer, Embedding
from document_models import Document, DocumentChunk
from schemas import (
    QuestionAnswerRequest, 
    QuestionAnswerResponse, 
    HealthResponse, 
    AuthHealthResponse,
    QuestionResponse,
    AnswerResponse
)
from enhanced_rag_service import EnhancedRAGService  # Use enhanced service
import crud
from simple_pdf_processor import SimplePDFProcessor

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize enhanced RAG service
rag_service = EnhancedRAGService()

# Create database tables
Base.metadata.create_all(bind=engine)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan manager"""
    # Startup
    logger.info("üöÄ Starting Enhanced PDF RAG Q&A API...")
    
    # Check DATABASE_URL
    database_url = os.getenv("DATABASE_URL")
    if database_url:
        logger.info(f"üìä Database URL configured: {database_url[:30]}...")
        try:
            db = SessionLocal()
            result = db.execute(text("SELECT 1"))
            result.fetchone()
            db.close()
            logger.info("‚úÖ Database connection successful!")
        except Exception as e:
            logger.error(f"‚ùå Database connection failed: {str(e)}")
    else:
        logger.error("‚ùå DATABASE_URL not configured!")
    
    # Check OpenAI
    if os.getenv("OPENAI_API_KEY"):
        logger.info("ü§ñ OpenAI API Key configured - Enhanced RAG enabled")
    else:
        logger.info("üé≠ Running in demo mode - Enhanced RAG with mock responses")
    
    yield
    
    # Shutdown
    logger.info("üõë Shutting down Enhanced PDF RAG Q&A API...")

# Initialize FastAPI app
app = FastAPI(
    title="Enhanced PDF RAG Q&A API",
    description="An advanced FastAPI backend for PDF document processing and contextual Q&A using enhanced RAG",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # In production, replace with specific origins
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Security
security = HTTPBearer()

# API Keys for development/demo
VALID_API_KEYS = {
    "dev-api-key-123",
    "test-api-key-456", 
    "demo-key-789",
    "qa-development-key",
    "master-dev-key"
}

def verify_api_key(credentials: HTTPAuthorizationCredentials = Depends(security)) -> str:
    """Verify API key from Authorization header"""
    api_key = credentials.credentials
    
    if api_key not in VALID_API_KEYS:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid API key",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    return api_key

@app.get("/", response_model=dict)
async def root():
    """Root endpoint"""
    return {
        "message": "Enhanced PDF RAG Q&A API",
        "version": "2.0.0",
        "status": "running",
        "features": [
            "Strict prioritization of document content",
            "Multi-strategy document search",
            "Historical Q&A integration",
            "GPT fallback for unknown questions",
            "Transparent source attribution"
        ],
        "endpoints": {
            "health": "/health",
            "auth_health": "/auth/health",
            "ask": "/ask",
            "questions": "/questions",
            "documents": "/documents",
            "upload": "/documents/upload"
        }
    }

@app.get("/health", response_model=HealthResponse)
async def health_check(db: Session = Depends(get_db)):
    """Health check endpoint"""
    try:
        db.execute(text("SELECT 1"))
        database_connected = True
    except Exception:
        database_connected = False
    
    return HealthResponse(
        status="healthy",
        message="Enhanced RAG API is running",
        timestamp=datetime.utcnow(),
        database_connected=database_connected,
        openai_configured=rag_service.openai_configured
    )

@app.get("/auth/health", response_model=AuthHealthResponse)
async def auth_health_check(api_key: str = Depends(verify_api_key)):
    """Authenticated health check endpoint"""
    return AuthHealthResponse(
        status="authenticated",
        message="API key is valid",
        timestamp=datetime.utcnow()
    )

@app.post("/ask", response_model=QuestionAnswerResponse)
async def ask_question(
    request: QuestionAnswerRequest,
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """Ask a question with strict prioritization: 1) Documents, 2) Historical Q&A, 3) GPT"""
    try:
        question_text = request.question.strip()
        
        if not question_text:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Question cannot be empty"
            )
        
        print(f"üîç Processing question with strict prioritization: {question_text[:50]}...")
        
        # Step 1: Analyze the question to understand intent and context
        question_analysis = await rag_service.analyze_question_intent(question_text)
        print(f"üß† Question analysis: {question_analysis['intent']} ({question_analysis['complexity']})")
        
        # Step 2: Generate embedding for semantic search
        query_embedding = await rag_service.generate_embedding(question_text)
        
        # Step 3: Process the question with strict prioritization
        response_data = await rag_service.process_question(
            db, question_text, query_embedding, question_analysis
        )
        
        # Step 4: Store the question and answer if not from historical Q&A
        if response_data.get("source_type") != "historical":
            # Store new question
            new_question = crud.create_question(db, crud.QuestionCreate(text=question_text))
            question_id = new_question.id
            
            # Store embedding
            crud.create_embedding(db, question_id, query_embedding)
            
            # Store answer
            new_answer = crud.create_answer(
                db, 
                crud.AnswerCreate(
                    question_id=question_id,
                    text=response_data['answer'],
                    confidence_score=response_data['confidence']
                )
            )
            answer_id = new_answer.id
            
            print(f"üíæ Stored new question and answer (source: {response_data.get('primary_source')}, confidence: {response_data['confidence']:.2f})")
        else:
            # Using historical Q&A
            question_id = response_data.get("question_id")
            answer_id = response_data.get("answer_id")
            print(f"üìö Using historical Q&A (question_id: {question_id})")
        
        # Prepare final response
        return QuestionAnswerResponse(
            answer=response_data['answer'],
            question_id=question_id,
            answer_id=answer_id,
            similarity_score=response_data.get('similarity', 0.0),
            is_cached=response_data.get("source_type") == "historical",
            source_documents=response_data.get('source_documents', [])
        )
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error processing question: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error processing question: {str(e)}"
        )

@app.get("/questions", response_model=List[QuestionResponse])
async def get_questions(
    skip: int = 0,
    limit: int = 100,
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """Get a list of questions"""
    questions = crud.get_questions(db, skip=skip, limit=limit)
    return questions

@app.get("/documents")
async def list_documents(
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """List all uploaded documents"""
    try:
        # Query documents table directly
        result = db.execute(text("""
            SELECT id, filename, original_filename, file_size, 
                   content_type, upload_date, processed, processing_status,
                   total_pages, total_chunks
            FROM documents 
            ORDER BY upload_date DESC
        """))
        
        documents = []
        for row in result:
            documents.append({
                "id": row[0],
                "filename": row[1],
                "original_filename": row[2],
                "file_size": row[3],
                "content_type": row[4],
                "upload_date": row[5],
                "processed": row[6],
                "processing_status": row[7],
                "total_pages": row[8],
                "total_chunks": row[9]
            })
        
        return {
            "documents": documents,
            "total": len(documents),
            "message": "Documents retrieved successfully"
        }
        
    except Exception as e:
        print(f"‚ùå Error listing documents: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error listing documents: {str(e)}"
        )

@app.post("/documents/upload")
async def upload_document(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """Upload and process a PDF document"""
    try:
        # Validate file type
        if not file.filename.lower().endswith('.pdf'):
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Only PDF files are supported"
            )
        
        # Read file content
        file_content = await file.read()
        
        if len(file_content) == 0:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Empty file uploaded"
            )
        
        # Generate unique filename
        file_extension = os.path.splitext(file.filename)[1]
        unique_filename = f"{uuid.uuid4()}{file_extension}"
        
        print(f"üì§ Uploading document: {file.filename} ({len(file_content)} bytes)")
        
        # Insert document record using SQLAlchemy ORM
        document = Document(
            filename=unique_filename,
            original_filename=file.filename,
            file_size=len(file_content),
            content_type="application/pdf",
            processing_status="uploaded"
        )
        
        db.add(document)
        db.commit()
        db.refresh(document)
        
        # Process PDF in background
        pdf_processor = SimplePDFProcessor(rag_service)
        background_tasks.add_task(
            pdf_processor.process_pdf_content,
            db,
            document.id,
            file_content
        )
        
        return {
            "message": "Document uploaded successfully and processing started",
            "document_id": document.id,
            "filename": file.filename,
            "file_size": len(file_content),
            "processing_status": "uploaded",
            "note": "PDF processing with enhanced RAG is running in the background. The system will extract content, generate embeddings, and enable contextual search."
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error uploading document: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error uploading document: {str(e)}"
        )

@app.delete("/documents/{document_id}")
async def delete_document(
    document_id: int,
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """Delete a document and all its chunks"""
    try:
        # Check if document exists
        result = db.execute(text("SELECT id FROM documents WHERE id = :id"), {"id": document_id})
        if not result.fetchone():
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="Document not found"
            )
        
        # Delete document (chunks will be deleted automatically due to CASCADE)
        db.execute(text("DELETE FROM documents WHERE id = :id"), {"id": document_id})
        db.commit()
        
        return {"message": "Document deleted successfully"}
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå Error deleting document: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error deleting document: {str(e)}"
        )

@app.get("/stats")
async def get_stats(
    db: Session = Depends(get_db),
    api_key: str = Depends(verify_api_key)
):
    """Get API statistics"""
    try:
        # Get counts from database
        question_count = db.execute(text("SELECT COUNT(*) FROM questions")).fetchone()[0]
        answer_count = db.execute(text("SELECT COUNT(*) FROM answers")).fetchone()[0]
        document_count = db.execute(text("SELECT COUNT(*) FROM documents")).fetchone()[0]
        chunk_count = db.execute(text("SELECT COUNT(*) FROM document_chunks")).fetchone()[0]
        
        return {
            "questions": question_count,
            "answers": answer_count,
            "documents": document_count,
            "chunks": chunk_count,
            "openai_configured": rag_service.openai_configured,
            "document_similarity_threshold": rag_service.document_similarity_threshold,
            "qa_similarity_threshold": rag_service.qa_similarity_threshold,
            "version": "2.0.0 - Enhanced RAG with Strict Prioritization"
        }
        
    except Exception as e:
        print(f"‚ùå Error getting stats: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error getting stats: {str(e)}"
        )

if __name__ == "__main__":
    port = int(os.getenv("PORT", 8000))
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=port,
        reload=True
    )
